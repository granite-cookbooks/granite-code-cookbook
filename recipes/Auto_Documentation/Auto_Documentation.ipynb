{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "toc_visible": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Auto-generating Documentation\n",
        "\n",
        "A blurb outlineing the notebook, and what we are doing\n",
        "\n",
        "## Install Dependencies"
      ],
      "metadata": {
        "id": "Q6rko_ANX0EC"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2zUHQD71qgqf",
        "outputId": "77eaf183-5535-4302-a0c4-3c7cb20db91c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting replicate\n",
            "  Downloading replicate-0.33.0-py3-none-any.whl.metadata (25 kB)\n",
            "Collecting httpx<1,>=0.21.0 (from replicate)\n",
            "  Downloading httpx-0.27.2-py3-none-any.whl.metadata (7.1 kB)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from replicate) (24.1)\n",
            "Requirement already satisfied: pydantic>1.10.7 in /usr/local/lib/python3.10/dist-packages (from replicate) (2.9.2)\n",
            "Requirement already satisfied: typing-extensions>=4.5.0 in /usr/local/lib/python3.10/dist-packages (from replicate) (4.12.2)\n",
            "Requirement already satisfied: anyio in /usr/local/lib/python3.10/dist-packages (from httpx<1,>=0.21.0->replicate) (3.7.1)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.10/dist-packages (from httpx<1,>=0.21.0->replicate) (2024.8.30)\n",
            "Collecting httpcore==1.* (from httpx<1,>=0.21.0->replicate)\n",
            "  Downloading httpcore-1.0.5-py3-none-any.whl.metadata (20 kB)\n",
            "Requirement already satisfied: idna in /usr/local/lib/python3.10/dist-packages (from httpx<1,>=0.21.0->replicate) (3.10)\n",
            "Requirement already satisfied: sniffio in /usr/local/lib/python3.10/dist-packages (from httpx<1,>=0.21.0->replicate) (1.3.1)\n",
            "Collecting h11<0.15,>=0.13 (from httpcore==1.*->httpx<1,>=0.21.0->replicate)\n",
            "  Downloading h11-0.14.0-py3-none-any.whl.metadata (8.2 kB)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.10/dist-packages (from pydantic>1.10.7->replicate) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.23.4 in /usr/local/lib/python3.10/dist-packages (from pydantic>1.10.7->replicate) (2.23.4)\n",
            "Requirement already satisfied: exceptiongroup in /usr/local/lib/python3.10/dist-packages (from anyio->httpx<1,>=0.21.0->replicate) (1.2.2)\n",
            "Downloading replicate-0.33.0-py3-none-any.whl (45 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m45.3/45.3 kB\u001b[0m \u001b[31m1.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading httpx-0.27.2-py3-none-any.whl (76 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m76.4/76.4 kB\u001b[0m \u001b[31m4.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading httpcore-1.0.5-py3-none-any.whl (77 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m77.9/77.9 kB\u001b[0m \u001b[31m5.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading h11-0.14.0-py3-none-any.whl (58 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m58.3/58.3 kB\u001b[0m \u001b[31m4.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: h11, httpcore, httpx, replicate\n",
            "Successfully installed h11-0.14.0 httpcore-1.0.5 httpx-0.27.2 replicate-0.33.0\n"
          ]
        }
      ],
      "source": [
        "!pip install replicate transformers"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Set Replicate Token"
      ],
      "metadata": {
        "id": "ydrVWz7EYHh9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "from google.colab import userdata\n",
        "\n",
        "os.environ['REPLICATE_API_TOKEN'] = userdata.get('REPLICATE_API_TOKEN')"
      ],
      "metadata": {
        "id": "TSkiGBY4qo32"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Define a function for downloading a repository\n",
        "\n",
        "A blurb about the following function\n",
        "\n",
        "`github_token` is optional, but if it is set you can access more endpoints and have a higher rate limit. More information here: https://docs.github.com/en/rest/authentication/authenticating-to-the-rest-api?apiVersion=2022-11-28"
      ],
      "metadata": {
        "id": "5d0sWaZ7YLHN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import requests\n",
        "from time import sleep\n",
        "\n",
        "def get_github_repo_contents(repo_url, directory_path, github_token = None):\n",
        "    # Extracting the owner and repo name from the URL\n",
        "    repo_parts = repo_url.rstrip('/').split('/')\n",
        "    owner = repo_parts[-2]\n",
        "    repo = repo_parts[-1]\n",
        "\n",
        "    api_url = f\"https://api.github.com/repos/{owner}/{repo}/contents/{directory_path}\"\n",
        "    if github_token is not None:\n",
        "      headers = {'Authorization': f'token {github_token}'}\n",
        "      response = requests.get(api_url, headers = headers)\n",
        "    else:\n",
        "      response = requests.get(api_url)\n",
        "    response.raise_for_status()\n",
        "\n",
        "    contents = response.json()\n",
        "\n",
        "    result = []\n",
        "\n",
        "    for item in contents:\n",
        "        if item['type'] == 'file':\n",
        "            file_response = requests.get(item['download_url'])\n",
        "            file_response.raise_for_status()\n",
        "            file_content = file_response.text\n",
        "            language = item['name'].split('.')[-1]\n",
        "            if language == 'py':\n",
        "                language = 'python'\n",
        "            elif language == 'js':\n",
        "                language = 'javascript'\n",
        "            result.append(f\"{item['path']}\\n```{language}\\n{file_content}\\n```\")\n",
        "        elif item['type'] == 'dir':\n",
        "            # Recursively go through subdirectories\n",
        "            subdirectory_contents = get_github_repo_contents(repo_url, item['path'], github_token)\n",
        "            result.append(subdirectory_contents)\n",
        "        sleep(0.1)\n",
        "\n",
        "    return \"\\n\\n\".join(result)\n"
      ],
      "metadata": {
        "id": "3JFi40LArpIa"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Get code from `ibm-granite-community/utils`\n",
        "\n",
        "Specify the `ibm_granite_community` directory because it has all of the functions."
      ],
      "metadata": {
        "id": "H-06VQn1YmtU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "prompt = get_github_repo_contents(\"https://github.com/ibm-granite-community/utils\", \"ibm_granite_community\")"
      ],
      "metadata": {
        "id": "k2wS6rGJsu-T"
      },
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Count the tokens\n",
        "\n",
        "Our model has a context window of 128k, which means the _input_ plus the _output_ can be no longer than 128k."
      ],
      "metadata": {
        "id": "HYuQmgRJY0n5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import AutoTokenizer\n",
        "\n",
        "model_path = \"ibm-granite/granite-8B-Code-instruct-128k\"\n",
        "tokenizer = AutoTokenizer.from_pretrained(model_path)\n",
        "\n",
        "print(f\"Your git repo load has {len(tokenizer(prompt, return_tensors='pt')['input_ids'][0])} tokens\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7JqmvTqbWPgl",
        "outputId": "fd23a408-e586-47aa-8e3b-d279608704e6"
      },
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Your git repo load has 714 tokens\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Create our prompt and call the model in Replicate\n",
        "\n",
        "Blurb about the following"
      ],
      "metadata": {
        "id": "ygNmITWQZAZ8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import replicate\n",
        "\n",
        "full_prompt = prompt + \"\"\"\n",
        "\n",
        "Provide detailed developer documentation for each function provided above.\n",
        "\n",
        "Response Template:\n",
        "## `function_name`\n",
        "\n",
        "* _param1_: (type) description\"\n",
        "\n",
        "Synopsis of the function\n",
        "\n",
        "_**returns**_:\n",
        "\"\"\"\n",
        "\n",
        "output = replicate.run(\n",
        "    \"ibm-granite/granite-8b-code-instruct-128k\",\n",
        "    input={\n",
        "\n",
        "        \"prompt\": full_prompt,\n",
        "        \"max_tokens\": 10000,\n",
        "        \"min_tokens\": 0,\n",
        "        \"temperature\": 0.75,\n",
        "        \"system_prompt\": \"You are a helpful assistant.\",\n",
        "        \"presence_penalty\": 0,\n",
        "        \"frequency_penalty\": 0\n",
        "    })\n",
        "\n",
        "\n",
        "print(\"\".join(output))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yu4HeuqWqvOj",
        "outputId": "f06270d8-7dc7-4adf-815e-3807457028a8"
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "## `find_langchain_model`\n",
            "\n",
            "* `platform`: (string) The platform to use for the model, either \"replicate\" or \"ollama\".\n",
            "* `model_id`: (string) The ID of the model to use.\n",
            "* `model_kwargs`: (dict) Additional keyword arguments to pass to the model constructor.\n",
            "\n",
            "Returns:\n",
            "- The loaded model object.\n",
            "\n",
            "Synopsis:\n",
            "The `find_langchain_model` function is used to load a model from either the Replicate or Ollama platform. It takes in the platform, model ID, and any additional keyword arguments for the model constructor.\n",
            "\n",
            "Example:\n",
            "```python\n",
            "model = find_langchain_model(\"replicate\", \"text-davinci-003\", temperature=0.8)\n",
            "```\n",
            "\n",
            "## `find_langchain_vector_db`\n",
            "\n",
            "* `provider`: (string) The provider of the vector database, either \"milvus\" or \"chroma\".\n",
            "* `embeddings_model`: (function) The function to use for embeddings.\n",
            "* `model_kwargs`: (dict) Additional keyword arguments to pass to the vector database constructor.\n",
            "\n",
            "Returns:\n",
            "- The loaded vector database object.\n",
            "\n",
            "Synopsis:\n",
            "The `find_langchain_vector_db` function is used to load a vector database from either Milvus or Chroma. It takes in the provider, embeddings model, and any additional keyword arguments for the vector database constructor.\n",
            "\n",
            "Example:\n",
            "```python\n",
            "vector_db = find_langchain_vector_db(\"milvus\", embeddings_model, dimension=128)\n",
            "```\n",
            "\n",
            "## `get_api_key`\n",
            "\n",
            "* None\n",
            "\n",
            "Returns:\n",
            "- The loaded API key as a string.\n",
            "\n",
            "Synopsis:\n",
            "The `get_api_key` function is used to load the API key for the Replicate API. It checks if the API key is available in Google Colab secrets, a `.env` file, or the user is prompted for the API key.\n",
            "\n",
            "Example:\n",
            "```python\n",
            "api_key = get_api_key()\n",
            "```\n",
            "\n",
            "## `set_api_key`\n",
            "\n",
            "* None\n",
            "\n",
            "Returns:\n",
            "- None\n",
            "\n",
            "Synopsis:\n",
            "The `set_api_key` function is used to set the API key for the Replicate API in the environment variables. If the API key is not already set, it will call the `get_api_key` function to get the API key and set it in the environment variables.\n",
            "\n",
            "Example:\n",
            "```python\n",
            "set_api_key()\n",
            "```\n",
            "\n"
          ]
        }
      ]
    }
  ]
}