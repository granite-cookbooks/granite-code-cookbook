{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "# Retrieval Augmented Generation (RAG) with WatsonX, Langchain, and Chroma\n",
    "\n",
    "Based on the IBM Cloud notebook [Use WatsonX, Chroma, and LangChain to answer questions (RAG)](https://dataplatform.cloud.ibm.com/exchange/public/entry/view/d3a5f957-a93b-46cd-82c1-c8d37d4f62c6?context=wx)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## In this notebook\n",
    "This notebook contains instructions for performing Retrieval Augumented Generation (RAG) in watsonx.ai. RAG is an architectural pattern that can be used to augment the performance of language models by recalling factual information from a knowledge base, and adding that information to the model query.\n",
    "\n",
    "RAG use cases include:\n",
    "- Customer service: Answering questions about a product or service using facts from the product documentation.\n",
    "- Domain knowledge: Exploring a specialized domain (e.g., finance) using facts from papers or articles in the knowledge base.\n",
    "- News chat: Chatting about current events by calling up relevant recent news articles.\n",
    "\n",
    "In its simplest form, RAG requires 3 steps:\n",
    "\n",
    "- Initial setup:\n",
    "  - Index knowledge-base passages for efficient retrieval. In this recipe, we take embeddings of the passages using WatsonX, and store them in a vector database.\n",
    "- Upon each user query:\n",
    "  - Retrieve relevant passages from the database. In this recipe, we using an embedding of the query to retrieve semantically similar passages.\n",
    "  - Generate a response by feeding retrieved passage into a large language model, along with the user query."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Setting up the environment\n",
    "\n",
    "Before you use the sample code in this notebook, you must perform the following setup tasks:\n",
    "\n",
    "-  Create a [Watson Machine Learning (WML) Service](https://cloud.ibm.com/catalog/services/watson-machine-learning) instance using the free plan. Information about how to create the instance can be found [here](https://dataplatform.cloud.ibm.com/docs/content/wsj/getting-started/wml-plans.html?context=wx&audience=wdp)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### Install and import the dependencies\n",
    "\n",
    "This notebook was tested with Python 3.10.15."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: exceptiongroup>=1.0.2 in /Users/fayvor/Dev/granite-code-cookbook/.venv/lib/python3.10/site-packages (from anyio->httpx<1,>=0.23.0->langsmith<0.2.0,>=0.1.117->langchain-core) (1.2.2)\n",
      "Requirement already satisfied: exceptiongroup>=1.0.2 in /Users/fayvor/Dev/granite-code-cookbook/.venv/lib/python3.10/site-packages (from anyio->httpx<1,>=0.23.0->langsmith<0.2.0,>=0.1.17->langchain) (1.2.2)\n",
      "Requirement already satisfied: typing-extensions>=4.1 in /Users/fayvor/Dev/granite-code-cookbook/.venv/lib/python3.10/site-packages (from anyio->httpx->ibm-watsonx-ai) (4.12.2)\n",
      "Requirement already satisfied: exceptiongroup>=1.0.2 in /Users/fayvor/Dev/granite-code-cookbook/.venv/lib/python3.10/site-packages (from anyio->httpx->ibm-watsonx-ai<2.0.0,>=1.1.9->langchain_ibm) (1.2.2)\n",
      "Requirement already satisfied: wget in /Users/fayvor/Dev/granite-code-cookbook/.venv/lib/python3.10/site-packages (3.2)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /Users/fayvor/Dev/granite-code-cookbook/.venv/lib/python3.10/site-packages (from sympy->torch>=1.11.0->sentence-transformers) (1.3.0)\n",
      "Requirement already satisfied: pyasn1<0.7.0,>=0.4.6 in /Users/fayvor/Dev/granite-code-cookbook/.venv/lib/python3.10/site-packages (from pyasn1-modules>=0.2.1->google-auth>=1.0.1->kubernetes>=28.1.0->chromadb) (0.6.1)\n",
      "Requirement already satisfied: typing-extensions>=4.6.1 in /Users/fayvor/Dev/granite-code-cookbook/.venv/lib/python3.10/site-packages (from pydantic) (4.12.2)\n",
      "Requirement already satisfied: greenlet!=0.4.17 in /Users/fayvor/Dev/granite-code-cookbook/.venv/lib/python3.10/site-packages (from sqlalchemy) (3.1.0)\n",
      "Requirement already satisfied: exceptiongroup>=1.0.2 in /Users/fayvor/Dev/granite-code-cookbook/.venv/lib/python3.10/site-packages (from anyio->httpx<1,>=0.23.0->langsmith<0.2.0,>=0.1.112->langchain-community) (1.2.2)\n"
     ]
    }
   ],
   "source": [
    "!pip install \"langchain-core\" -U | tail -n 1\n",
    "!pip install \"langchain\" | tail -n 1\n",
    "!pip install \"ibm-watsonx-ai\" | tail -n 1\n",
    "!pip install \"langchain_ibm\" | tail -n 1\n",
    "!pip install \"wget\" | tail -n 1\n",
    "!pip install \"sentence-transformers\" | tail -n 1\n",
    "!pip install \"chromadb\" | tail -n 1\n",
    "!pip install \"pydantic\" | tail -n 1\n",
    "!pip install \"sqlalchemy\" | tail -n 1\n",
    "!pip install \"langchain-community\" | tail -n 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### Set up the WatsonX API connection credentials\n",
    "Provide the IBM Cloud user API key in an environment variable called `WATSONX_API_KEY`, or at the input. \n",
    "\n",
    "If you don't have an API key, you should be able to [create one here](https://cloud.ibm.com/iam/apikeys). For more details, see the <a href=\"https://cloud.ibm.com/docs/account?topic=account-userapikey&interface=ui\" target=\"_blank\" rel=\"noopener no referrer\">documentation</a>.\n",
    "\n",
    "NOTE: A string that starts with `cpd-apikey` or `APIKey` is _not_ the key value, but the name or id of the key."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Please enter your apikey (hit enter):  ········\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "try:\n",
    "    apikey = os.environ[\"WATSONX_APIKEY\"]\n",
    "except KeyError:\n",
    "    from getpass import getpass\n",
    "    apikey = getpass(\"Please enter your apikey (hit enter): \")\n",
    "\n",
    "credentials = {\n",
    "    \"url\": \"https://us-south.ml.cloud.ibm.com\",\n",
    "    \"apikey\": apikey,\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### Provide the project id\n",
    "\n",
    "Provide the WatsonX Project Id in an environment variable called `WATSONX_PROJECT_ID`, or at the input.\n",
    "\n",
    "You can find the `Project ID` for your project like this:\n",
    "* Visit the [Projects page in WatsonX](https://dataplatform.cloud.ibm.com/projects/?context=wx).\n",
    "* From the list of projects, click on your project's name to get to the individual Project page.\n",
    "* From there, navigate to the Manage tab and to the General view, where you will see the `Project ID` in the Details section."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Please enter your project_id (hit enter):  hello\n"
     ]
    }
   ],
   "source": [
    "try:\n",
    "    project_id = os.environ[\"WATSONX_PROJECT_ID\"]\n",
    "except KeyError:\n",
    "    project_id = input(\"Please enter your project_id (hit enter): \")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Building the Database\n",
    "\n",
    "The most common approach in RAG is to create dense vector representations of the knowledge base in order to calculate the semantic similarity to a given user query.\n",
    "\n",
    "In this basic example, we take the State of the Union speech content (filename), split it into chunks, embed it using an open-source embedding model, load it into <a href=\"https://www.trychroma.com/\" target=\"_blank\" rel=\"noopener no referrer\">Chroma</a>, and then query it."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Download the document\n",
    "\n",
    "Here we use President Biden's State of the Union address from March 1, 2022."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "import wget\n",
    "\n",
    "filename = 'state_of_the_union.txt'\n",
    "url = 'https://raw.github.com/IBM/watson-machine-learning-samples/master/cloud/data/foundation_models/state_of_the_union.txt'\n",
    "\n",
    "if not os.path.isfile(filename):\n",
    "    wget.download(url, out=filename)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Split the document into chunks\n",
    "\n",
    "Split the document into text segments that can fit into the model's context window."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "from langchain.document_loaders import TextLoader\n",
    "from langchain.text_splitter import CharacterTextSplitter\n",
    "from langchain.vectorstores import Chroma\n",
    "\n",
    "loader = TextLoader(filename)\n",
    "documents = loader.load()\n",
    "text_splitter = CharacterTextSplitter(chunk_size=1000, chunk_overlap=0)\n",
    "texts = text_splitter.split_documents(documents)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### Create an embedding function\n",
    "\n",
    "Note that you can feed a custom embedding function to be used by chromadb. The performance of Chroma db may differ depending on the embedding model used. In following example we use watsonx.ai Embedding service. We can check available embedding models using `get_embedding_model_specs`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'total_count': 7,\n",
       " 'limit': 100,\n",
       " 'first': {'href': 'https://us-south.ml.cloud.ibm.com/ml/v1/foundation_model_specs?version=2023-09-30&filters=function_embedding'},\n",
       " 'resources': [{'model_id': 'cross-encoder/ms-marco-minilm-l-12-v2',\n",
       "   'label': 'ms-marco-minilm-l-12-v2',\n",
       "   'provider': 'cross-encoder',\n",
       "   'source': 'cross-encoder',\n",
       "   'functions': [{'id': 'embedding'}],\n",
       "   'short_description': 'Used for Information Retrieval: Encode and sort a query will all possible passages.',\n",
       "   'long_description': 'The model can be used for Information Retrieval: Given a query, encode the query will all possible passages (e.g. retrieved with ElasticSearch). Then sort the passages in a decreasing order.',\n",
       "   'input_tier': 'class_c1',\n",
       "   'output_tier': 'class_c1',\n",
       "   'number_params': '33.4m',\n",
       "   'limits': {'lite': {'call_time': '5m0s'},\n",
       "    'v2-professional': {'call_time': '10m0s'},\n",
       "    'v2-standard': {'call_time': '10m0s'}},\n",
       "   'lifecycle': [{'id': 'available', 'start_date': '2024-09-17'}]},\n",
       "  {'model_id': 'ibm/slate-125m-english-rtrvr',\n",
       "   'label': 'slate-125m-english-rtrvr',\n",
       "   'provider': 'IBM',\n",
       "   'source': 'IBM',\n",
       "   'functions': [{'id': 'embedding'}],\n",
       "   'short_description': 'An embedding model. It has 125 million parameters and an embedding dimension of 768.',\n",
       "   'long_description': \"This model follows the standard 'sentence transformers' approach, relying on bi-encoders. It generates embeddings for various inputs such as queries, passages, or documents. The training objective is to maximize cosine similarity between two text pieces: text A (query text) and text B (passage text). This process yields sentence embeddings q and p, allowing for comparison through cosine similarity.\",\n",
       "   'input_tier': 'class_c1',\n",
       "   'output_tier': 'class_c1',\n",
       "   'number_params': '125m',\n",
       "   'limits': {'lite': {'call_time': '5m0s'},\n",
       "    'v2-professional': {'call_time': '10m0s'},\n",
       "    'v2-standard': {'call_time': '10m0s'}},\n",
       "   'lifecycle': [{'id': 'available', 'start_date': '2024-04-18'}]},\n",
       "  {'model_id': 'ibm/slate-125m-english-rtrvr-v2',\n",
       "   'label': 'slate-125m-english-rtrvr-v2',\n",
       "   'provider': 'IBM',\n",
       "   'source': 'IBM',\n",
       "   'functions': [{'id': 'embedding'}],\n",
       "   'short_description': 'An embedding model with 512 token limit. It has 125 million parameters and an embedding dimension of 768.',\n",
       "   'long_description': \"This model follows the standard 'sentence transformers' approach, relying on bi-encoders. It generates embeddings for various inputs such as queries, passages, or documents. The training objective is to maximize cosine similarity between two text pieces: text A (query text) and text B (passage text). This process yields sentence embeddings q and p, allowing for comparison through cosine similarity.\",\n",
       "   'input_tier': 'class_c1',\n",
       "   'output_tier': 'class_c1',\n",
       "   'number_params': '125m',\n",
       "   'limits': {'lite': {'call_time': '5m0s'},\n",
       "    'v2-professional': {'call_time': '10m0s'},\n",
       "    'v2-standard': {'call_time': '10m0s'}}},\n",
       "  {'model_id': 'ibm/slate-30m-english-rtrvr',\n",
       "   'label': 'slate-30m-english-rtrvr',\n",
       "   'provider': 'IBM',\n",
       "   'source': 'IBM',\n",
       "   'functions': [{'id': 'embedding'}],\n",
       "   'short_description': 'An embedding model. It has 30 million parameters and an embedding dimension of 384.',\n",
       "   'long_description': \"This model follows the standard 'sentence transformers' approach, relying on bi-encoders. It generates embeddings for various inputs such as queries, passages, or documents. The training objective is to maximize cosine similarity between two text pieces: text A (query text) and text B (passage text). This process yields sentence embeddings q and p, allowing for comparison through cosine similarity.\",\n",
       "   'input_tier': 'class_c1',\n",
       "   'output_tier': 'class_c1',\n",
       "   'number_params': '30m',\n",
       "   'limits': {'lite': {'call_time': '5m0s'},\n",
       "    'v2-professional': {'call_time': '10m0s'},\n",
       "    'v2-standard': {'call_time': '10m0s'}},\n",
       "   'lifecycle': [{'id': 'available', 'start_date': '2024-04-18'}]},\n",
       "  {'model_id': 'ibm/slate-30m-english-rtrvr-v2',\n",
       "   'label': 'slate-30m-english-rtrvr-v2',\n",
       "   'provider': 'IBM',\n",
       "   'source': 'IBM',\n",
       "   'functions': [{'id': 'embedding'}],\n",
       "   'short_description': 'An embedding model with 512 token limit. It has 30 million parameters and an embedding dimension of 384.',\n",
       "   'long_description': \"This model follows the standard 'sentence transformers' approach, relying on bi-encoders. It generates embeddings for various inputs such as queries, passages, or documents. The training objective is to maximize cosine similarity between two text pieces: text A (query text) and text B (passage text). This process yields sentence embeddings q and p, allowing for comparison through cosine similarity.\",\n",
       "   'input_tier': 'class_c1',\n",
       "   'output_tier': 'class_c1',\n",
       "   'number_params': '30m',\n",
       "   'limits': {'lite': {'call_time': '5m0s'},\n",
       "    'v2-professional': {'call_time': '10m0s'},\n",
       "    'v2-standard': {'call_time': '10m0s'}},\n",
       "   'lifecycle': [{'id': 'available', 'start_date': '2024-08-15'}]},\n",
       "  {'model_id': 'intfloat/multilingual-e5-large',\n",
       "   'label': 'multilingual-e5-large',\n",
       "   'provider': 'intfloat',\n",
       "   'source': 'intfloat',\n",
       "   'functions': [{'id': 'embedding'}],\n",
       "   'short_description': 'An embedding model. It has 560 million parameters, has 24 layers and the embedding size is 1024.',\n",
       "   'long_description': 'This model gets continually trained on a mixture of multilingual datasets. It supports 100 languages from xlm-roberta.',\n",
       "   'input_tier': 'class_c1',\n",
       "   'output_tier': 'class_c1',\n",
       "   'number_params': '560m',\n",
       "   'limits': {'lite': {'call_time': '5m0s'},\n",
       "    'v2-professional': {'call_time': '10m0s'},\n",
       "    'v2-standard': {'call_time': '10m0s'}},\n",
       "   'lifecycle': [{'id': 'available', 'start_date': '2024-05-16'}]},\n",
       "  {'model_id': 'sentence-transformers/all-minilm-l12-v2',\n",
       "   'label': 'all-minilm-l12-v2',\n",
       "   'provider': 'sentence-transformers',\n",
       "   'source': 'sentence-transformers',\n",
       "   'functions': [{'id': 'embedding'}],\n",
       "   'short_description': 'An embedding model with 128 token limit. It has 33.4 million parameters and an embedding dimension of 384.',\n",
       "   'long_description': 'This model follows sentence transformers approach, it maps sentences & paragraphs to a 384 dimensional dense vector space and can be used for tasks like clustering or semantic search.',\n",
       "   'input_tier': 'class_c1',\n",
       "   'output_tier': 'class_c1',\n",
       "   'number_params': '33.4m',\n",
       "   'limits': {'lite': {'call_time': '5m0s'},\n",
       "    'v2-professional': {'call_time': '10m0s'},\n",
       "    'v2-standard': {'call_time': '10m0s'}},\n",
       "   'lifecycle': [{'id': 'available', 'start_date': '2024-05-16'}]}]}"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from ibm_watsonx_ai.foundation_models.utils import get_embedding_model_specs\n",
    "\n",
    "get_embedding_model_specs(credentials.get('url'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from langchain_ibm import WatsonxEmbeddings\n",
    "from ibm_watsonx_ai.foundation_models.utils.enums import EmbeddingTypes\n",
    "\n",
    "embeddings = WatsonxEmbeddings(\n",
    "    model_id=EmbeddingTypes.IBM_SLATE_30M_ENG.value,\n",
    "    url=credentials[\"url\"],\n",
    "    apikey=credentials[\"apikey\"],\n",
    "    project_id=project_id\n",
    "    )\n",
    "docsearch = Chroma.from_documents(texts, embeddings)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Compatibility watsonx.ai Embeddings with LangChain\n",
    "\n",
    " LangChain retrievals use `embed_documents` and `embed_query` under the hood to generate embedding vectors for uploaded documents and user query respectively."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Help on class WatsonxEmbeddings in module langchain_ibm.embeddings:\n",
      "\n",
      "class WatsonxEmbeddings(pydantic.main.BaseModel, langchain_core.embeddings.embeddings.Embeddings)\n",
      " |  WatsonxEmbeddings(*, model_id: str, project_id: Optional[str] = None, space_id: Optional[str] = None, url: pydantic.types.SecretStr = None, apikey: Optional[pydantic.types.SecretStr] = None, token: Optional[pydantic.types.SecretStr] = None, password: Optional[pydantic.types.SecretStr] = None, username: Optional[pydantic.types.SecretStr] = None, instance_id: Optional[pydantic.types.SecretStr] = None, version: Optional[pydantic.types.SecretStr] = None, params: Optional[dict] = None, verify: Union[str, bool, NoneType] = None, watsonx_embed: ibm_watsonx_ai.foundation_models.embeddings.embeddings.Embeddings = None, watsonx_client: Optional[ibm_watsonx_ai.client.APIClient] = None) -> None\n",
      " |  \n",
      " |  IBM watsonx.ai embedding models.\n",
      " |  \n",
      " |  Method resolution order:\n",
      " |      WatsonxEmbeddings\n",
      " |      pydantic.main.BaseModel\n",
      " |      langchain_core.embeddings.embeddings.Embeddings\n",
      " |      abc.ABC\n",
      " |      builtins.object\n",
      " |  \n",
      " |  Methods defined here:\n",
      " |  \n",
      " |  embed_documents(self, texts: 'List[str]') -> 'List[List[float]]'\n",
      " |      Embed search docs.\n",
      " |  \n",
      " |  embed_query(self, text: 'str') -> 'List[float]'\n",
      " |      Embed query text.\n",
      " |  \n",
      " |  validate_environment(self) -> 'Self'\n",
      " |      Validate that credentials and python package exists in environment.\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Data descriptors defined here:\n",
      " |  \n",
      " |  __weakref__\n",
      " |      list of weak references to the object (if defined)\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Data and other attributes defined here:\n",
      " |  \n",
      " |  __abstractmethods__ = frozenset()\n",
      " |  \n",
      " |  __annotations__ = {'apikey': 'Optional[SecretStr]', 'instance_id': 'Op...\n",
      " |  \n",
      " |  __class_vars__ = set()\n",
      " |  \n",
      " |  __private_attributes__ = {}\n",
      " |  \n",
      " |  __pydantic_complete__ = True\n",
      " |  \n",
      " |  __pydantic_core_schema__ = {'function': {'function': <function Watsonx...\n",
      " |  \n",
      " |  __pydantic_custom_init__ = False\n",
      " |  \n",
      " |  __pydantic_decorators__ = DecoratorInfos(validators={}, field_validato...\n",
      " |  \n",
      " |  __pydantic_generic_metadata__ = {'args': (), 'origin': None, 'paramete...\n",
      " |  \n",
      " |  __pydantic_parent_namespace__ = None\n",
      " |  \n",
      " |  __pydantic_post_init__ = None\n",
      " |  \n",
      " |  __pydantic_serializer__ = SchemaSerializer(serializer=Model(\n",
      " |      Model...\n",
      " |  \n",
      " |  __pydantic_validator__ = SchemaValidator(title=\"WatsonxEmbeddings\", va...\n",
      " |  \n",
      " |  __signature__ = <Signature (*, model_id: str, project_id: Option...ibm...\n",
      " |  \n",
      " |  model_computed_fields = {}\n",
      " |  \n",
      " |  model_config = {'arbitrary_types_allowed': True, 'extra': 'forbid', 'p...\n",
      " |  \n",
      " |  model_fields = {'apikey': FieldInfo(annotation=Union[SecretStr, NoneTy...\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Methods inherited from pydantic.main.BaseModel:\n",
      " |  \n",
      " |  __copy__(self) -> 'Self'\n",
      " |      Returns a shallow copy of the model.\n",
      " |  \n",
      " |  __deepcopy__(self, memo: 'dict[int, Any] | None' = None) -> 'Self'\n",
      " |      Returns a deep copy of the model.\n",
      " |  \n",
      " |  __delattr__(self, item: 'str') -> 'Any'\n",
      " |      Implement delattr(self, name).\n",
      " |  \n",
      " |  __eq__(self, other: 'Any') -> 'bool'\n",
      " |      Return self==value.\n",
      " |  \n",
      " |  __getattr__(self, item: 'str') -> 'Any'\n",
      " |  \n",
      " |  __getstate__(self) -> 'dict[Any, Any]'\n",
      " |  \n",
      " |  __init__(self, /, **data: 'Any') -> 'None'\n",
      " |      Create a new model by parsing and validating input data from keyword arguments.\n",
      " |      \n",
      " |      Raises [`ValidationError`][pydantic_core.ValidationError] if the input data cannot be\n",
      " |      validated to form a valid model.\n",
      " |      \n",
      " |      `self` is explicitly positional-only to allow `self` as a field name.\n",
      " |  \n",
      " |  __iter__(self) -> 'TupleGenerator'\n",
      " |      So `dict(model)` works.\n",
      " |  \n",
      " |  __pretty__(self, fmt: 'typing.Callable[[Any], Any]', **kwargs: 'Any') -> 'typing.Generator[Any, None, None]'\n",
      " |      Used by devtools (https://python-devtools.helpmanual.io/) to pretty print objects.\n",
      " |  \n",
      " |  __repr__(self) -> 'str'\n",
      " |      Return repr(self).\n",
      " |  \n",
      " |  __repr_args__(self) -> '_repr.ReprArgs'\n",
      " |  \n",
      " |  __repr_name__(self) -> 'str'\n",
      " |      Name of the instance's class, used in __repr__.\n",
      " |  \n",
      " |  __repr_str__(self, join_str: 'str') -> 'str'\n",
      " |  \n",
      " |  __rich_repr__(self) -> 'RichReprResult'\n",
      " |      Used by Rich (https://rich.readthedocs.io/en/stable/pretty.html) to pretty print objects.\n",
      " |  \n",
      " |  __setattr__(self, name: 'str', value: 'Any') -> 'None'\n",
      " |      Implement setattr(self, name, value).\n",
      " |  \n",
      " |  __setstate__(self, state: 'dict[Any, Any]') -> 'None'\n",
      " |  \n",
      " |  __str__(self) -> 'str'\n",
      " |      Return str(self).\n",
      " |  \n",
      " |  copy(self, *, include: 'AbstractSetIntStr | MappingIntStrAny | None' = None, exclude: 'AbstractSetIntStr | MappingIntStrAny | None' = None, update: 'Dict[str, Any] | None' = None, deep: 'bool' = False) -> 'Self'\n",
      " |      Returns a copy of the model.\n",
      " |      \n",
      " |      !!! warning \"Deprecated\"\n",
      " |          This method is now deprecated; use `model_copy` instead.\n",
      " |      \n",
      " |      If you need `include` or `exclude`, use:\n",
      " |      \n",
      " |      ```py\n",
      " |      data = self.model_dump(include=include, exclude=exclude, round_trip=True)\n",
      " |      data = {**data, **(update or {})}\n",
      " |      copied = self.model_validate(data)\n",
      " |      ```\n",
      " |      \n",
      " |      Args:\n",
      " |          include: Optional set or mapping specifying which fields to include in the copied model.\n",
      " |          exclude: Optional set or mapping specifying which fields to exclude in the copied model.\n",
      " |          update: Optional dictionary of field-value pairs to override field values in the copied model.\n",
      " |          deep: If True, the values of fields that are Pydantic models will be deep-copied.\n",
      " |      \n",
      " |      Returns:\n",
      " |          A copy of the model with included, excluded and updated fields as specified.\n",
      " |  \n",
      " |  dict(self, *, include: 'IncEx | None' = None, exclude: 'IncEx | None' = None, by_alias: 'bool' = False, exclude_unset: 'bool' = False, exclude_defaults: 'bool' = False, exclude_none: 'bool' = False) -> 'Dict[str, Any]'\n",
      " |  \n",
      " |  json(self, *, include: 'IncEx | None' = None, exclude: 'IncEx | None' = None, by_alias: 'bool' = False, exclude_unset: 'bool' = False, exclude_defaults: 'bool' = False, exclude_none: 'bool' = False, encoder: 'Callable[[Any], Any] | None' = PydanticUndefined, models_as_dict: 'bool' = PydanticUndefined, **dumps_kwargs: 'Any') -> 'str'\n",
      " |  \n",
      " |  model_copy(self, *, update: 'dict[str, Any] | None' = None, deep: 'bool' = False) -> 'Self'\n",
      " |      Usage docs: https://docs.pydantic.dev/2.9/concepts/serialization/#model_copy\n",
      " |      \n",
      " |      Returns a copy of the model.\n",
      " |      \n",
      " |      Args:\n",
      " |          update: Values to change/add in the new model. Note: the data is not validated\n",
      " |              before creating the new model. You should trust this data.\n",
      " |          deep: Set to `True` to make a deep copy of the model.\n",
      " |      \n",
      " |      Returns:\n",
      " |          New model instance.\n",
      " |  \n",
      " |  model_dump(self, *, mode: \"Literal['json', 'python'] | str\" = 'python', include: 'IncEx | None' = None, exclude: 'IncEx | None' = None, context: 'Any | None' = None, by_alias: 'bool' = False, exclude_unset: 'bool' = False, exclude_defaults: 'bool' = False, exclude_none: 'bool' = False, round_trip: 'bool' = False, warnings: \"bool | Literal['none', 'warn', 'error']\" = True, serialize_as_any: 'bool' = False) -> 'dict[str, Any]'\n",
      " |      Usage docs: https://docs.pydantic.dev/2.9/concepts/serialization/#modelmodel_dump\n",
      " |      \n",
      " |      Generate a dictionary representation of the model, optionally specifying which fields to include or exclude.\n",
      " |      \n",
      " |      Args:\n",
      " |          mode: The mode in which `to_python` should run.\n",
      " |              If mode is 'json', the output will only contain JSON serializable types.\n",
      " |              If mode is 'python', the output may contain non-JSON-serializable Python objects.\n",
      " |          include: A set of fields to include in the output.\n",
      " |          exclude: A set of fields to exclude from the output.\n",
      " |          context: Additional context to pass to the serializer.\n",
      " |          by_alias: Whether to use the field's alias in the dictionary key if defined.\n",
      " |          exclude_unset: Whether to exclude fields that have not been explicitly set.\n",
      " |          exclude_defaults: Whether to exclude fields that are set to their default value.\n",
      " |          exclude_none: Whether to exclude fields that have a value of `None`.\n",
      " |          round_trip: If True, dumped values should be valid as input for non-idempotent types such as Json[T].\n",
      " |          warnings: How to handle serialization errors. False/\"none\" ignores them, True/\"warn\" logs errors,\n",
      " |              \"error\" raises a [`PydanticSerializationError`][pydantic_core.PydanticSerializationError].\n",
      " |          serialize_as_any: Whether to serialize fields with duck-typing serialization behavior.\n",
      " |      \n",
      " |      Returns:\n",
      " |          A dictionary representation of the model.\n",
      " |  \n",
      " |  model_dump_json(self, *, indent: 'int | None' = None, include: 'IncEx | None' = None, exclude: 'IncEx | None' = None, context: 'Any | None' = None, by_alias: 'bool' = False, exclude_unset: 'bool' = False, exclude_defaults: 'bool' = False, exclude_none: 'bool' = False, round_trip: 'bool' = False, warnings: \"bool | Literal['none', 'warn', 'error']\" = True, serialize_as_any: 'bool' = False) -> 'str'\n",
      " |      Usage docs: https://docs.pydantic.dev/2.9/concepts/serialization/#modelmodel_dump_json\n",
      " |      \n",
      " |      Generates a JSON representation of the model using Pydantic's `to_json` method.\n",
      " |      \n",
      " |      Args:\n",
      " |          indent: Indentation to use in the JSON output. If None is passed, the output will be compact.\n",
      " |          include: Field(s) to include in the JSON output.\n",
      " |          exclude: Field(s) to exclude from the JSON output.\n",
      " |          context: Additional context to pass to the serializer.\n",
      " |          by_alias: Whether to serialize using field aliases.\n",
      " |          exclude_unset: Whether to exclude fields that have not been explicitly set.\n",
      " |          exclude_defaults: Whether to exclude fields that are set to their default value.\n",
      " |          exclude_none: Whether to exclude fields that have a value of `None`.\n",
      " |          round_trip: If True, dumped values should be valid as input for non-idempotent types such as Json[T].\n",
      " |          warnings: How to handle serialization errors. False/\"none\" ignores them, True/\"warn\" logs errors,\n",
      " |              \"error\" raises a [`PydanticSerializationError`][pydantic_core.PydanticSerializationError].\n",
      " |          serialize_as_any: Whether to serialize fields with duck-typing serialization behavior.\n",
      " |      \n",
      " |      Returns:\n",
      " |          A JSON string representation of the model.\n",
      " |  \n",
      " |  model_post_init(self, _BaseModel__context: 'Any') -> 'None'\n",
      " |      Override this method to perform additional initialization after `__init__` and `model_construct`.\n",
      " |      This is useful if you want to do some validation that requires the entire model to be initialized.\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Class methods inherited from pydantic.main.BaseModel:\n",
      " |  \n",
      " |  __class_getitem__(typevar_values: 'type[Any] | tuple[type[Any], ...]') -> 'type[BaseModel] | _forward_ref.PydanticRecursiveRef' from pydantic._internal._model_construction.ModelMetaclass\n",
      " |  \n",
      " |  __get_pydantic_core_schema__(source: 'type[BaseModel]', handler: 'GetCoreSchemaHandler', /) -> 'CoreSchema' from pydantic._internal._model_construction.ModelMetaclass\n",
      " |      Hook into generating the model's CoreSchema.\n",
      " |      \n",
      " |      Args:\n",
      " |          source: The class we are generating a schema for.\n",
      " |              This will generally be the same as the `cls` argument if this is a classmethod.\n",
      " |          handler: A callable that calls into Pydantic's internal CoreSchema generation logic.\n",
      " |      \n",
      " |      Returns:\n",
      " |          A `pydantic-core` `CoreSchema`.\n",
      " |  \n",
      " |  __get_pydantic_json_schema__(core_schema: 'CoreSchema', handler: 'GetJsonSchemaHandler', /) -> 'JsonSchemaValue' from pydantic._internal._model_construction.ModelMetaclass\n",
      " |      Hook into generating the model's JSON schema.\n",
      " |      \n",
      " |      Args:\n",
      " |          core_schema: A `pydantic-core` CoreSchema.\n",
      " |              You can ignore this argument and call the handler with a new CoreSchema,\n",
      " |              wrap this CoreSchema (`{'type': 'nullable', 'schema': current_schema}`),\n",
      " |              or just call the handler with the original schema.\n",
      " |          handler: Call into Pydantic's internal JSON schema generation.\n",
      " |              This will raise a `pydantic.errors.PydanticInvalidForJsonSchema` if JSON schema\n",
      " |              generation fails.\n",
      " |              Since this gets called by `BaseModel.model_json_schema` you can override the\n",
      " |              `schema_generator` argument to that function to change JSON schema generation globally\n",
      " |              for a type.\n",
      " |      \n",
      " |      Returns:\n",
      " |          A JSON schema, as a Python object.\n",
      " |  \n",
      " |  __pydantic_init_subclass__(**kwargs: 'Any') -> 'None' from pydantic._internal._model_construction.ModelMetaclass\n",
      " |      This is intended to behave just like `__init_subclass__`, but is called by `ModelMetaclass`\n",
      " |      only after the class is actually fully initialized. In particular, attributes like `model_fields` will\n",
      " |      be present when this is called.\n",
      " |      \n",
      " |      This is necessary because `__init_subclass__` will always be called by `type.__new__`,\n",
      " |      and it would require a prohibitively large refactor to the `ModelMetaclass` to ensure that\n",
      " |      `type.__new__` was called in such a manner that the class would already be sufficiently initialized.\n",
      " |      \n",
      " |      This will receive the same `kwargs` that would be passed to the standard `__init_subclass__`, namely,\n",
      " |      any kwargs passed to the class definition that aren't used internally by pydantic.\n",
      " |      \n",
      " |      Args:\n",
      " |          **kwargs: Any keyword arguments passed to the class definition that aren't used internally\n",
      " |              by pydantic.\n",
      " |  \n",
      " |  construct(_fields_set: 'set[str] | None' = None, **values: 'Any') -> 'Self' from pydantic._internal._model_construction.ModelMetaclass\n",
      " |  \n",
      " |  from_orm(obj: 'Any') -> 'Self' from pydantic._internal._model_construction.ModelMetaclass\n",
      " |  \n",
      " |  model_construct(_fields_set: 'set[str] | None' = None, **values: 'Any') -> 'Self' from pydantic._internal._model_construction.ModelMetaclass\n",
      " |      Creates a new instance of the `Model` class with validated data.\n",
      " |      \n",
      " |      Creates a new model setting `__dict__` and `__pydantic_fields_set__` from trusted or pre-validated data.\n",
      " |      Default values are respected, but no other validation is performed.\n",
      " |      \n",
      " |      !!! note\n",
      " |          `model_construct()` generally respects the `model_config.extra` setting on the provided model.\n",
      " |          That is, if `model_config.extra == 'allow'`, then all extra passed values are added to the model instance's `__dict__`\n",
      " |          and `__pydantic_extra__` fields. If `model_config.extra == 'ignore'` (the default), then all extra passed values are ignored.\n",
      " |          Because no validation is performed with a call to `model_construct()`, having `model_config.extra == 'forbid'` does not result in\n",
      " |          an error if extra values are passed, but they will be ignored.\n",
      " |      \n",
      " |      Args:\n",
      " |          _fields_set: A set of field names that were originally explicitly set during instantiation. If provided,\n",
      " |              this is directly used for the [`model_fields_set`][pydantic.BaseModel.model_fields_set] attribute.\n",
      " |              Otherwise, the field names from the `values` argument will be used.\n",
      " |          values: Trusted or pre-validated data dictionary.\n",
      " |      \n",
      " |      Returns:\n",
      " |          A new instance of the `Model` class with validated data.\n",
      " |  \n",
      " |  model_json_schema(by_alias: 'bool' = True, ref_template: 'str' = '#/$defs/{model}', schema_generator: 'type[GenerateJsonSchema]' = <class 'pydantic.json_schema.GenerateJsonSchema'>, mode: 'JsonSchemaMode' = 'validation') -> 'dict[str, Any]' from pydantic._internal._model_construction.ModelMetaclass\n",
      " |      Generates a JSON schema for a model class.\n",
      " |      \n",
      " |      Args:\n",
      " |          by_alias: Whether to use attribute aliases or not.\n",
      " |          ref_template: The reference template.\n",
      " |          schema_generator: To override the logic used to generate the JSON schema, as a subclass of\n",
      " |              `GenerateJsonSchema` with your desired modifications\n",
      " |          mode: The mode in which to generate the schema.\n",
      " |      \n",
      " |      Returns:\n",
      " |          The JSON schema for the given model class.\n",
      " |  \n",
      " |  model_parametrized_name(params: 'tuple[type[Any], ...]') -> 'str' from pydantic._internal._model_construction.ModelMetaclass\n",
      " |      Compute the class name for parametrizations of generic classes.\n",
      " |      \n",
      " |      This method can be overridden to achieve a custom naming scheme for generic BaseModels.\n",
      " |      \n",
      " |      Args:\n",
      " |          params: Tuple of types of the class. Given a generic class\n",
      " |              `Model` with 2 type variables and a concrete model `Model[str, int]`,\n",
      " |              the value `(str, int)` would be passed to `params`.\n",
      " |      \n",
      " |      Returns:\n",
      " |          String representing the new class where `params` are passed to `cls` as type variables.\n",
      " |      \n",
      " |      Raises:\n",
      " |          TypeError: Raised when trying to generate concrete names for non-generic models.\n",
      " |  \n",
      " |  model_rebuild(*, force: 'bool' = False, raise_errors: 'bool' = True, _parent_namespace_depth: 'int' = 2, _types_namespace: 'dict[str, Any] | None' = None) -> 'bool | None' from pydantic._internal._model_construction.ModelMetaclass\n",
      " |      Try to rebuild the pydantic-core schema for the model.\n",
      " |      \n",
      " |      This may be necessary when one of the annotations is a ForwardRef which could not be resolved during\n",
      " |      the initial attempt to build the schema, and automatic rebuilding fails.\n",
      " |      \n",
      " |      Args:\n",
      " |          force: Whether to force the rebuilding of the model schema, defaults to `False`.\n",
      " |          raise_errors: Whether to raise errors, defaults to `True`.\n",
      " |          _parent_namespace_depth: The depth level of the parent namespace, defaults to 2.\n",
      " |          _types_namespace: The types namespace, defaults to `None`.\n",
      " |      \n",
      " |      Returns:\n",
      " |          Returns `None` if the schema is already \"complete\" and rebuilding was not required.\n",
      " |          If rebuilding _was_ required, returns `True` if rebuilding was successful, otherwise `False`.\n",
      " |  \n",
      " |  model_validate(obj: 'Any', *, strict: 'bool | None' = None, from_attributes: 'bool | None' = None, context: 'Any | None' = None) -> 'Self' from pydantic._internal._model_construction.ModelMetaclass\n",
      " |      Validate a pydantic model instance.\n",
      " |      \n",
      " |      Args:\n",
      " |          obj: The object to validate.\n",
      " |          strict: Whether to enforce types strictly.\n",
      " |          from_attributes: Whether to extract data from object attributes.\n",
      " |          context: Additional context to pass to the validator.\n",
      " |      \n",
      " |      Raises:\n",
      " |          ValidationError: If the object could not be validated.\n",
      " |      \n",
      " |      Returns:\n",
      " |          The validated model instance.\n",
      " |  \n",
      " |  model_validate_json(json_data: 'str | bytes | bytearray', *, strict: 'bool | None' = None, context: 'Any | None' = None) -> 'Self' from pydantic._internal._model_construction.ModelMetaclass\n",
      " |      Usage docs: https://docs.pydantic.dev/2.9/concepts/json/#json-parsing\n",
      " |      \n",
      " |      Validate the given JSON data against the Pydantic model.\n",
      " |      \n",
      " |      Args:\n",
      " |          json_data: The JSON data to validate.\n",
      " |          strict: Whether to enforce types strictly.\n",
      " |          context: Extra variables to pass to the validator.\n",
      " |      \n",
      " |      Returns:\n",
      " |          The validated Pydantic model.\n",
      " |      \n",
      " |      Raises:\n",
      " |          ValidationError: If `json_data` is not a JSON string or the object could not be validated.\n",
      " |  \n",
      " |  model_validate_strings(obj: 'Any', *, strict: 'bool | None' = None, context: 'Any | None' = None) -> 'Self' from pydantic._internal._model_construction.ModelMetaclass\n",
      " |      Validate the given object with string data against the Pydantic model.\n",
      " |      \n",
      " |      Args:\n",
      " |          obj: The object containing string data to validate.\n",
      " |          strict: Whether to enforce types strictly.\n",
      " |          context: Extra variables to pass to the validator.\n",
      " |      \n",
      " |      Returns:\n",
      " |          The validated Pydantic model.\n",
      " |  \n",
      " |  parse_file(path: 'str | Path', *, content_type: 'str | None' = None, encoding: 'str' = 'utf8', proto: 'DeprecatedParseProtocol | None' = None, allow_pickle: 'bool' = False) -> 'Self' from pydantic._internal._model_construction.ModelMetaclass\n",
      " |  \n",
      " |  parse_obj(obj: 'Any') -> 'Self' from pydantic._internal._model_construction.ModelMetaclass\n",
      " |  \n",
      " |  parse_raw(b: 'str | bytes', *, content_type: 'str | None' = None, encoding: 'str' = 'utf8', proto: 'DeprecatedParseProtocol | None' = None, allow_pickle: 'bool' = False) -> 'Self' from pydantic._internal._model_construction.ModelMetaclass\n",
      " |  \n",
      " |  schema(by_alias: 'bool' = True, ref_template: 'str' = '#/$defs/{model}') -> 'Dict[str, Any]' from pydantic._internal._model_construction.ModelMetaclass\n",
      " |  \n",
      " |  schema_json(*, by_alias: 'bool' = True, ref_template: 'str' = '#/$defs/{model}', **dumps_kwargs: 'Any') -> 'str' from pydantic._internal._model_construction.ModelMetaclass\n",
      " |  \n",
      " |  update_forward_refs(**localns: 'Any') -> 'None' from pydantic._internal._model_construction.ModelMetaclass\n",
      " |  \n",
      " |  validate(value: 'Any') -> 'Self' from pydantic._internal._model_construction.ModelMetaclass\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Readonly properties inherited from pydantic.main.BaseModel:\n",
      " |  \n",
      " |  __fields_set__\n",
      " |  \n",
      " |  model_extra\n",
      " |      Get extra fields set during validation.\n",
      " |      \n",
      " |      Returns:\n",
      " |          A dictionary of extra fields, or `None` if `config.extra` is not set to `\"allow\"`.\n",
      " |  \n",
      " |  model_fields_set\n",
      " |      Returns the set of fields that have been explicitly set on this model instance.\n",
      " |      \n",
      " |      Returns:\n",
      " |          A set of strings representing the fields that have been set,\n",
      " |              i.e. that were not filled from defaults.\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Data descriptors inherited from pydantic.main.BaseModel:\n",
      " |  \n",
      " |  __dict__\n",
      " |      dictionary for instance variables (if defined)\n",
      " |  \n",
      " |  __pydantic_extra__\n",
      " |  \n",
      " |  __pydantic_fields_set__\n",
      " |  \n",
      " |  __pydantic_private__\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Data and other attributes inherited from pydantic.main.BaseModel:\n",
      " |  \n",
      " |  __hash__ = None\n",
      " |  \n",
      " |  __pydantic_root_model__ = False\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Methods inherited from langchain_core.embeddings.embeddings.Embeddings:\n",
      " |  \n",
      " |  async aembed_documents(self, texts: List[str]) -> List[List[float]]\n",
      " |      Asynchronous Embed search docs.\n",
      " |      \n",
      " |      Args:\n",
      " |          texts: List of text to embed.\n",
      " |      \n",
      " |      Returns:\n",
      " |          List of embeddings.\n",
      " |  \n",
      " |  async aembed_query(self, text: str) -> List[float]\n",
      " |      Asynchronous Embed query text.\n",
      " |      \n",
      " |      Args:\n",
      " |          text: Text to embed.\n",
      " |      \n",
      " |      Returns:\n",
      " |          Embedding.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "help(WatsonxEmbeddings)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Configuring the Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "IBM watsonx foundation models are among the [LLM models supported by Langchain](https://python.langchain.com/docs/integrations/llms/ibm_watsonx/)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### Select the model\n",
    "Specify the `model_id` of the model that will be used for inferencing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<ModelTypes.GRANITE_13B_CHAT_V2: 'ibm/granite-13b-chat-v2'>"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from ibm_watsonx_ai.foundation_models.utils.enums import ModelTypes\n",
    "\n",
    "model_id = ModelTypes.GRANITE_13B_CHAT_V2\n",
    "model_id"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### Define the model parameters\n",
    "Provide the parameters that will be used to configure the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "from ibm_watsonx_ai.metanames import GenTextParamsMetaNames as GenParams\n",
    "from ibm_watsonx_ai.foundation_models.utils.enums import DecodingMethods\n",
    "\n",
    "parameters = {\n",
    "    GenParams.DECODING_METHOD: DecodingMethods.GREEDY,\n",
    "    GenParams.MIN_NEW_TOKENS: 1,\n",
    "    GenParams.MAX_NEW_TOKENS: 100,\n",
    "    GenParams.STOP_SEQUENCES: [\"<|endoftext|>\"]\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Initialize the WatsonX model\n",
    "Using a CustomLLM wrapper from Langchain, initialize the model with defined parameters and the model specified above."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "from langchain_ibm import WatsonxLLM\n",
    "\n",
    "watsonx_granite = WatsonxLLM(\n",
    "    model_id=model_id.value,\n",
    "    url=credentials.get(\"url\"),\n",
    "    apikey=credentials.get(\"apikey\"),\n",
    "    project_id=project_id,\n",
    "    params=parameters\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Answering Queries"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Automate the RAG pipeline\n",
    "\n",
    "Build a question-answering chain with the model and the document retriever."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.chains import RetrievalQA\n",
    "\n",
    "qa = RetrievalQA.from_chain_type(llm=watsonx_granite, chain_type=\"stuff\", retriever=docsearch.as_retriever())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### Generate a retrieval-augmented response to a question"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "Use the question-answering chain to process the query. \n",
    "\n",
    "NOTE: This may take a little while if you are on the 'Lite' Watson Machine Learning plan."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'query': 'What did the president say about Ketanji Brown Jackson',\n",
       " 'result': ' The president said, \"One of our nation’s top legal minds, who will continue Justice Breyer’s legacy of excellence.\" This statement was made in reference to Ketanji Brown Jackson, who was nominated by the president to serve on the United States Supreme Court.'}"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "query = \"What did the president say about Ketanji Brown Jackson\"\n",
    "qa.invoke(query)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
