{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3e98b2a4-cf47-4523-bd07-827683728d31",
   "metadata": {},
   "source": [
    "# Use Remote and Local Granite Code Models with LangChain"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "00a45854-f221-466b-a0b4-78effeae9f41",
   "metadata": {},
   "source": [
    "## Introduction and Setup\n",
    "\n",
    "This notebook demonstrates using inference calls against a model hosted remotely on [Replicate](https://replicate.com/) and locally using [Ollama](https://ollama.com/)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a9b04485-3c77-40c3-a4ba-0a901f747f42",
   "metadata": {},
   "source": [
    "### Install Granite `utils` package\n",
    "\n",
    "This package is a thin shim with various functions that are required for notebooks.\n",
    "\n",
    "To see the implementation of its functions, see the [utils repo](https://github.com/ibm-granite-community/utils/tree/main)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "119fc048",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "!pip install git+https://github.com/ibm-granite-community/utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "83dfc528-7220-4c9f-ae67-07b3f37a46d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from ibm_granite_community.langchain_utils import find_langchain_model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "39f2db6c-f3cc-48a1-94c8-d12849446a77",
   "metadata": {},
   "source": [
    "### Define a Prompt\n",
    "\n",
    "The sections below demonstrate remote options and a local option for model inference.\n",
    "\n",
    "Each will perform a blocking call using the following prompt:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "02f99de7-ff2e-4ae4-b1f2-1ac4453b4c19",
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt = \"\"\"\n",
    "    Show me a SQL query that fetches all columns for the first 50 rows\n",
    "    in a table named 'users'.\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ab1f48d-a625-4210-80ef-a505c728b331",
   "metadata": {},
   "source": [
    "## Remote Model using Replicate"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3386acab-a8c6-41cc-b9b8-e20494ca4828",
   "metadata": {},
   "source": [
    "### Establish Replicate Account\n",
    "\n",
    "To use this remote option, create an account at [Replicate](https://replicate.com)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b3ab4d4-b6ee-4bac-8969-46b0204169af",
   "metadata": {},
   "source": [
    "### Add credit to your Replicate Account (optional)\n",
    "\n",
    "To remove a barrier to entry to try the Granite Code models on the Replicate platform,\n",
    "use [this link](https://replicate.com/invites/a8717bfe-2f3d-4a52-88ed-1356231cdf03) to add a\n",
    "small amount of credit to your Replicate account."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a3c0dce-3630-4408-bd51-23db676874cf",
   "metadata": {},
   "source": [
    "### Provide your API Token\n",
    "\n",
    "Obtain your `REPLICATE_API_TOKEN` at [replicate.com/account/api-tokens](https://replicate.com/account/api-tokens)\n",
    "\n",
    "There are three ways to provide this value to the cells below.  In order of precedence:\n",
    "\n",
    "1. As an environment variable\n",
    "2. As a Google colab secret\n",
    "3. Supplied by the user using `getpass()`"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0db3e69f-82cb-424d-8358-d981453aab93",
   "metadata": {},
   "source": [
    "### Choose a Model\n",
    "\n",
    "Two Granite Code models are available in the [`ibm-granite`](https://replicate.com/ibm-granite) org at Replicate.\n",
    "\n",
    "The `find_langchain_model` function below imports the `replicate` package.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "2eeb4c2e-ec15-4b73-8229-35dae503115c",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_id = \"ibm-granite/granite-8b-code-instruct-128k\"\n",
    "# model_id = \"ibm-granite/granite-20b-code-instruct-8k\"\n",
    "\n",
    "model = find_langchain_model(platform=\"Replicate\", model_id=model_id)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d6bcc704-3cab-4da5-8ada-9032d5bafdb4",
   "metadata": {},
   "source": [
    "### Perform Inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79a5b2e1-f7eb-4de3-bfb9-f049b0c3fe10",
   "metadata": {},
   "outputs": [],
   "source": [
    "response = model.invoke(prompt)\n",
    "\n",
    "print(f\"Granite response from Replicate: {response}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2236c0a3-398e-4370-a9c3-261b22d44e34",
   "metadata": {},
   "source": [
    "## Local Model using Ollama"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f4bd9d6-044c-4287-baf2-925a8f6e14e6",
   "metadata": {},
   "source": [
    "### Install Dependencies\n",
    "\n",
    "[Download and Start Ollama](https://ollama.com/download)\n",
    "\n",
    "Then pull a model:\n",
    "\n",
    "- Granite Code 20b: `ollama pull granite-code:20b`\n",
    "- Granite Code 8b: `ollama pull granite-code:8b`\n",
    "- Granite Code 3b: `ollama pull granite-code:3b`"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e92ff5c-510f-4ed2-9688-6831b6b91a4d",
   "metadata": {},
   "source": [
    "### Choose a Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "937957fd-36c0-4c0f-b91d-afd8de1447ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "# model_id = \"granite-code:3b\"\n",
    "model_id = \"granite-code:8b\"\n",
    "# model_id = \"granite-code:20b\"\n",
    "\n",
    "model = find_langchain_model(platform=\"ollama\", model_id=model_id)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e6a18e8d-e828-4acf-854e-350c3cee7f8e",
   "metadata": {},
   "source": [
    "### Perform Inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82e1a2e2-d222-4308-a572-784ca8b62c86",
   "metadata": {},
   "outputs": [],
   "source": [
    "response = model.invoke(prompt)\n",
    "\n",
    "print(f\"Granite response from Ollama: {response}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7828a665",
   "metadata": {},
   "source": [
    "## Remote Model using IBM WatsonX"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d18460e3",
   "metadata": {},
   "source": [
    "### Establish a WatsonX Account\n",
    "\n",
    "To use this remote option, create an account on [WatsonX](https://www.ibm.com/watsonx)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "556e261e",
   "metadata": {},
   "source": [
    "### Provide the Environment Variables\n",
    "\n",
    "There are three ways to provide the environment variables required by `find_langchain_model()` below.  In order of precedence:\n",
    "\n",
    "1. Directly as an environment variable in the python environment where the jupyter notebook is running.\n",
    "2. As a Google Colab secret, if you are running the notebook in Colab.\n",
    "3. Supplied by the user in a prompt during execution of the notebook."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c07c7c9a",
   "metadata": {},
   "source": [
    "### Provide your API Key\n",
    "\n",
    "Obtain your `WATSONX_APIKEY` by generating a [Platform API Key](https://www.ibm.com/docs/en/watsonx/watsonxdata/1.0.x?topic=started-generating-api-keys) on the watsonx.data web client.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "73ddc7d6",
   "metadata": {},
   "source": [
    "### Provide your Project Id\n",
    "\n",
    "Get your `WATSONX_PROJECT_ID` from the [WatsonX](https://www.ibm.com/watsonx) web client by following [these instructions](https://dataplatform.cloud.ibm.com/docs/content/wsj/analyze-data/fm-project-id.html?context=wx)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b76cdf0",
   "metadata": {},
   "source": [
    "### Provide your Base WatsonX URL\n",
    "\n",
    "Get your `WATSONX_URL` by viewing the details for the service instance from the Cloud Pak for Data web client, as described in [these watsonx.ai setup instructions](https://ibm.github.io/watsonx-ai-python-sdk/setup_cpd.html).\n",
    "\n",
    "As an example, your `WATSONX_URL` may be `https://us-south.ml.cloud.ibm.com` for the Dallas zone."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "35dbaee4",
   "metadata": {},
   "source": [
    "### Choose a Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "86a7ef73",
   "metadata": {},
   "outputs": [],
   "source": [
    "# model_id = \"ibm/granite-3b-code-instruct\"\n",
    "model_id = \"ibm/granite-8b-code-instruct\"\n",
    "# model_id = \"ibm/granite-20b-code-instruct\"\n",
    "# model_id = \"ibm/granite-34b-code-instruct\"\n",
    "\n",
    "import os\n",
    "model = find_langchain_model(platform=\"watsonx\", model_id=model_id)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a7f4db5e",
   "metadata": {},
   "source": [
    "### Perform Inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ddfdb7ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "response = model.invoke(prompt)\n",
    "\n",
    "print(f\"Granite response from WatsonX: {response}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
