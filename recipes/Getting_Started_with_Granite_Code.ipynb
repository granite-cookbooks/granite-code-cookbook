{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3e98b2a4-cf47-4523-bd07-827683728d31",
   "metadata": {},
   "source": [
    "# Use Granite Code Hosted on Replicate"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "00a45854-f221-466b-a0b4-78effeae9f41",
   "metadata": {},
   "source": [
    "## Introduction\n",
    "\n",
    "This notebook demonstrates using inference calls against a model hosted on [Replicate](https://replicate.com/).  To see how you can use [Ollama](https://ollama.com/) to host models locally instead, see the [Continue VSCode](Continue_VSCode/Continue_VSCode.ipynb) recipe.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3386acab-a8c6-41cc-b9b8-e20494ca4828",
   "metadata": {},
   "source": [
    "## Replicate Credit\n",
    "\n",
    "To remove a barrier to entry to try the Granite Code models on the Replicate platform,\n",
    "use [this link](https://replicate.com/invites/a8717bfe-2f3d-4a52-88ed-1356231cdf03) to add a\n",
    "small amount of credit to your Replicate account.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a9b04485-3c77-40c3-a4ba-0a901f747f42",
   "metadata": {},
   "source": [
    "## Install Replicate package"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1b43bcc-34d4-46ae-818e-fab2762ef86f",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install replicate"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a3c0dce-3630-4408-bd51-23db676874cf",
   "metadata": {},
   "source": [
    "## Provide your API Token\n",
    "\n",
    "This guide will demonstrate a basic inference call using the `replicate` package.\n",
    "\n",
    "To establish an authenticated session, provide your [Replicate API Token](https://replicate.com/account/api-tokens)\n",
    "to the cell when prompted below.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc5fa737-fbd4-422e-bed5-efae32e8c736",
   "metadata": {},
   "outputs": [],
   "source": [
    "import getpass, os\n",
    "\n",
    "replicate_api_token = getpass.getpass()\n",
    "\n",
    "os.environ[\"REPLICATE_API_TOKEN\"] = replicate_api_token"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0db3e69f-82cb-424d-8358-d981453aab93",
   "metadata": {},
   "source": [
    "## Choose a Model\n",
    "\n",
    "Two Granite Code models are available in the [`ibm-granite`](https://replicate.com/ibm-granite) org at Replicate.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2eeb4c2e-ec15-4b73-8229-35dae503115c",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_id = \"ibm-granite/granite-8b-code-instruct-128k\"\n",
    "# model_id = \"ibm-granite/granite-20b-code-instruct-8k\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "39f2db6c-f3cc-48a1-94c8-d12849446a77",
   "metadata": {},
   "source": [
    "## Define a Prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02f99de7-ff2e-4ae4-b1f2-1ac4453b4c19",
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt = \"\"\"\n",
    "    Show me a SQL query that fetches all columns for the first 50 rows\n",
    "    in a table named 'users'.\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d6bcc704-3cab-4da5-8ada-9032d5bafdb4",
   "metadata": {},
   "source": [
    "## Perform Blocking Inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "faeb924c-f39b-4510-b66b-23dc68c5287f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import replicate\n",
    "\n",
    "output = replicate.run(model_id,\n",
    "    input={\n",
    "        \"system_prompt\": \"You are a helpful assistant\",\n",
    "        \"max_new_tokens\": 100,\n",
    "        \"prompt\": prompt\n",
    "    }\n",
    ")\n",
    "\n",
    "print(''.join(output))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "238f7668",
   "metadata": {},
   "source": [
    "## Perform Asynchronous Inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "736d4153-3900-473c-a46b-d5e326dfb929",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = replicate.models.get(model_id)\n",
    "\n",
    "prediction = replicate.predictions.create(\n",
    "  model=model,\n",
    "  input={\"prompt\": prompt}\n",
    ")\n",
    "\n",
    "# The `create` call doesn't block, so we can do other work. Here, we'll just wait.\n",
    "prediction.wait()\n",
    "\n",
    "print(''.join(prediction.output))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
