{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "vscode": {
     "languageId": "shellscript"
    }
   },
   "source": [
    "# Running a Coding Assistant in VSCode using Continue and Granite Code"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "# Ollama\n",
    "### Install Ollama\n",
    "[Download the Ollama server](https://ollama.com/download) from the Ollama website, or install it with homebrew and start the server.\n",
    "\n",
    "`% brew install ollama`\n",
    "\n",
    "`% ollama serve`\n",
    "\n",
    "### Install a Model with Ollama\n",
    "\n",
    "Install a model with ollama, which will download a manifest and then the model files:\n",
    "\n",
    "```\n",
    "% ollama pull granite-code:20b\n",
    "```\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "# Continue in VSCode\n",
    "\n",
    "### Install Continue in VSCode\n",
    "Follow the [Continue Quickstart Docs](https://docs.continue.dev/quickstart) to install the Continue extension for VSCode. Once Continue is installed, you should see its icon in the left nav bar in VSCode. Selecting that will bring up the configuration window, and later the chat window.\n",
    "\n",
    "### Configure a Granite Code model in Continue\n",
    "\n",
    "After setting up Continue, you will need to configure a new model. Navigate to the Continue extension by clicking the icon in the left nav bar. If you are not presented with configuration options, click on the \"+\" button in the top bar of the chat window and selecting \"Add Model\" from the model dropdown.\n",
    "\n",
    "![alt text](Continue_VSCode.files/AddNewModel.png)\n",
    "\n",
    "Select \"Start with a Provider\", then select \"Ollama\" from the provider list.\n",
    "\n",
    "![alt text](Continue_VSCode.files/SelectOllamaProvider.png)\n",
    "\n",
    "The following will be added to your Continue config at `~/.continue/config.json`, which you can view by searching for `> Continue: Open config.json` in VSCode:\n",
    "\n",
    "```\n",
    "{\n",
    "   \"models\": [\n",
    "     {\n",
    "      \"model\": \"AUTODETECT\",\n",
    "      \"title\": \"Ollama\",\n",
    "      \"apiBase\": \"http://localhost:11434\",\n",
    "      \"provider\": \"ollama\"\n",
    "    }\n",
    "...\n",
    "```\n",
    "\n",
    "Now all models you have installed with Ollama will be available in the Continue chat window. \n",
    "Note: After pulling new models with ollama, you may need to restart VSCode to get Continue to autodetect them for the model dropdown in its chat window.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Granite Code for Chat\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "### Use the Granite Code model in Continue\n",
    "\n",
    "Select the Granite Code Model from the model dropdown in the Continue chat window:\n",
    "\n",
    "![alt text](Continue_VSCode.files/SelectGraniteModel.png)\n",
    "\n",
    "Now you have a chat window for the Granite Code model in your IDE!\n",
    "\n",
    "![alt text](Continue_VSCode.files/CodeChatOllamaGC20b.png)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Try Code Generation in this Notebook\n",
    "With this notebook open in VSCode, and your cursor in the code cell below, press `cmd+I` and enter the following text:\n",
    "\n",
    "`Write a function that adds two numbers together and returns the sum, and use that function to solve an example problem.`\n",
    "\n",
    "Granite Code will generate the following code (or similar):\n",
    "\n",
    "```\n",
    "def add(a, b):\n",
    "    return a + b\n",
    "\n",
    "result = add(2, 3)\n",
    "print(result)\n",
    "```\n",
    "\n",
    "You can then press \"Accept\" and run the code in the cell."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The sum of 3 and 5 is 8.\n"
     ]
    }
   ],
   "source": [
    "def add_numbers(a, b):\n",
    "    return a + b\n",
    "\n",
    "result = add_numbers(3, 5)\n",
    "print(f\"The sum of 3 and 5 is {result}.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Granite Code for Tab Autocompletion"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Configure a model for Tab Autocompletion\n",
    "\n",
    "In the search bar, type `> Continue` and click `Open config.json`.\n",
    "\n",
    "![Edit Continue configuration](Continue_VSCode.files/EditContinueConfig.png)\n",
    "\n",
    "Modify the Tab Autocomplete config entry to look like this:\n",
    "\n",
    "```\n",
    "  \"tabAutocompleteModel\": {\n",
    "    \"title\": \"Ollama Granite Code 3b\",\n",
    "    \"provider\": \"ollama\",\n",
    "    \"model\": \"granite-code:3b\"\n",
    "  },\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Use Tab Autocompletion\n",
    "\n",
    "In the editor, start typing a function name, or write a comment, and the assistant will propose code. Press `tab` to accept.\n",
    "\n",
    "![Tab Autocomplete example](Continue_VSCode.files/TabAutocompletion.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Have fun!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "## References\n",
    "\n",
    "* [Gabe Goodhart: Build a local AI co-pilot using IBM Granite Code, Ollama, and Continue](https://developer.ibm.com/tutorials/awb-local-ai-copilot-ibm-granite-code-ollama-continue/)\n",
    "* [Install Continue in VSCode - Quickstart](https://https://docs.continue.dev/quickstart)\n",
    "* [Download and run Ollama](https://ollama.com/download)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
