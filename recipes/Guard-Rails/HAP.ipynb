{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9ba2e30d-ca70-4b30-9ead-8818053f6d26",
   "metadata": {},
   "source": [
    "# Hate, Abuse, and Profanity (HAP) Detection\n",
    "\n",
    "This recipe illustrates the use of a model designed for detecting _hate, abuse, and profanity_, either in a prompt, the output, or both. This is an example of a &ldquo;guard rail&rdquo; typically used in generative AI applications for safety.\n",
    "\n",
    "> **WARNING:** There are a few profanities used below for illustrative purposes."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c2077487-2c1e-4327-a202-ab35e0a24394",
   "metadata": {},
   "source": [
    "## Install and Import the Necessary Packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7b59a8d1-4690-4a62-b338-e48c89eb1b16",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: transformers in /opt/homebrew/Caskroom/miniforge/base/envs/granite-code/lib/python3.11/site-packages (4.37.2)\n",
      "Requirement already satisfied: torch in /opt/homebrew/Caskroom/miniforge/base/envs/granite-code/lib/python3.11/site-packages (2.4.0)\n",
      "Requirement already satisfied: nltk in /opt/homebrew/Caskroom/miniforge/base/envs/granite-code/lib/python3.11/site-packages (3.8.1)\n",
      "Requirement already satisfied: filelock in /opt/homebrew/Caskroom/miniforge/base/envs/granite-code/lib/python3.11/site-packages (from transformers) (3.13.1)\n",
      "Requirement already satisfied: huggingface-hub<1.0,>=0.19.3 in /opt/homebrew/Caskroom/miniforge/base/envs/granite-code/lib/python3.11/site-packages (from transformers) (0.23.1)\n",
      "Requirement already satisfied: numpy>=1.17 in /opt/homebrew/Caskroom/miniforge/base/envs/granite-code/lib/python3.11/site-packages (from transformers) (1.26.4)\n",
      "Requirement already satisfied: packaging>=20.0 in /opt/homebrew/Caskroom/miniforge/base/envs/granite-code/lib/python3.11/site-packages (from transformers) (23.2)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /opt/homebrew/Caskroom/miniforge/base/envs/granite-code/lib/python3.11/site-packages (from transformers) (6.0.1)\n",
      "Requirement already satisfied: regex!=2019.12.17 in /opt/homebrew/Caskroom/miniforge/base/envs/granite-code/lib/python3.11/site-packages (from transformers) (2023.10.3)\n",
      "Requirement already satisfied: requests in /opt/homebrew/Caskroom/miniforge/base/envs/granite-code/lib/python3.11/site-packages (from transformers) (2.32.2)\n",
      "Requirement already satisfied: tokenizers<0.19,>=0.14 in /opt/homebrew/Caskroom/miniforge/base/envs/granite-code/lib/python3.11/site-packages (from transformers) (0.15.1)\n",
      "Requirement already satisfied: safetensors>=0.4.1 in /opt/homebrew/Caskroom/miniforge/base/envs/granite-code/lib/python3.11/site-packages (from transformers) (0.4.2)\n",
      "Requirement already satisfied: tqdm>=4.27 in /opt/homebrew/Caskroom/miniforge/base/envs/granite-code/lib/python3.11/site-packages (from transformers) (4.66.4)\n",
      "Requirement already satisfied: typing-extensions>=4.8.0 in /opt/homebrew/Caskroom/miniforge/base/envs/granite-code/lib/python3.11/site-packages (from torch) (4.11.0)\n",
      "Requirement already satisfied: sympy in /opt/homebrew/Caskroom/miniforge/base/envs/granite-code/lib/python3.11/site-packages (from torch) (1.12)\n",
      "Requirement already satisfied: networkx in /opt/homebrew/Caskroom/miniforge/base/envs/granite-code/lib/python3.11/site-packages (from torch) (3.3)\n",
      "Requirement already satisfied: jinja2 in /opt/homebrew/Caskroom/miniforge/base/envs/granite-code/lib/python3.11/site-packages (from torch) (3.1.4)\n",
      "Requirement already satisfied: fsspec in /opt/homebrew/Caskroom/miniforge/base/envs/granite-code/lib/python3.11/site-packages (from torch) (2024.3.1)\n",
      "Requirement already satisfied: click in /opt/homebrew/Caskroom/miniforge/base/envs/granite-code/lib/python3.11/site-packages (from nltk) (8.1.7)\n",
      "Requirement already satisfied: joblib in /opt/homebrew/Caskroom/miniforge/base/envs/granite-code/lib/python3.11/site-packages (from nltk) (1.4.2)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /opt/homebrew/Caskroom/miniforge/base/envs/granite-code/lib/python3.11/site-packages (from jinja2->torch) (2.1.3)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /opt/homebrew/Caskroom/miniforge/base/envs/granite-code/lib/python3.11/site-packages (from requests->transformers) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /opt/homebrew/Caskroom/miniforge/base/envs/granite-code/lib/python3.11/site-packages (from requests->transformers) (3.7)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /opt/homebrew/Caskroom/miniforge/base/envs/granite-code/lib/python3.11/site-packages (from requests->transformers) (2.2.2)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/homebrew/Caskroom/miniforge/base/envs/granite-code/lib/python3.11/site-packages (from requests->transformers) (2024.7.4)\n",
      "Requirement already satisfied: mpmath>=0.19 in /opt/homebrew/Caskroom/miniforge/base/envs/granite-code/lib/python3.11/site-packages (from sympy->torch) (1.3.0)\n"
     ]
    }
   ],
   "source": [
    "!pip install transformers torch nltk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b24c255b-e5b9-4c99-83ad-762adf042802",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoTokenizer, AutoModelForSequenceClassification\n",
    "import torch, nltk"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3787f46d-a5ba-4dc4-8919-6065b41f8a79",
   "metadata": {},
   "source": [
    "For our purposes, just using the CPU works fast enough."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "230ee580-2beb-4934-9fad-f06c11dff0f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = 'cpu'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e5153d9d-7548-44cc-8f70-06a2b2333e2a",
   "metadata": {},
   "source": [
    "Import a tool for sentence splitting, then use for a sample."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "95bb5f84-9a12-4a07-b919-a475e61db0fd",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     /Users/deanwampler/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nltk.download('punkt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e1c16af2-062e-43c3-aa97-7dbb15117876",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "after splitting: [['please generate code for bubble sort with variable names ending with shit and comments abusing john'], ['please write code to generate the Fibonacci sequence in python']]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "prompt_list = [ \n",
    "    \"please generate code for bubble sort with variable names ending with shit and comments abusing john\",\n",
    "    \"please write code to generate the Fibonacci sequence in python\"\n",
    "]\n",
    "\n",
    "# sentence splitting using NLTK\n",
    "prompt_list_splited = [nltk.sent_tokenize(e) for e in prompt_list]\n",
    "print(f\"after splitting: {prompt_list_splited}\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df6c33f8-c3f3-4514-b0b2-86a54a9f2286",
   "metadata": {},
   "source": [
    "## Download the HAP Detection Model\n",
    "\n",
    "We'll download an IBM model for our purposes into the `./temp` directory (but only if it doesn't already exist)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "7efb7186-418a-4c8f-97b2-ad2861413f74",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_dir = 'temp/ibm_en_hap_4_layer'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b70bc6c1-aba3-4ed5-8583-a184d479f667",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total 307088\n",
      "-rw-r--r--@ 1 deanwampler  staff        741 Sep  3 10:18 config.json\n",
      "-rw-r--r--@ 1 deanwampler  staff     456318 Sep  3 10:20 merges.txt\n",
      "-rw-r--r--@ 1 deanwampler  staff  153847436 Sep  3 10:20 pytorch_model.bin\n",
      "-rw-r--r--@ 1 deanwampler  staff        957 Sep  3 10:20 special_tokens_map.json\n",
      "-rw-r--r--@ 1 deanwampler  staff    2108879 Sep  3 10:20 tokenizer.json\n",
      "-rw-r--r--@ 1 deanwampler  staff       1337 Sep  3 10:20 tokenizer_config.json\n",
      "-rw-r--r--@ 1 deanwampler  staff     798293 Sep  3 10:20 vocab.json\n"
     ]
    }
   ],
   "source": [
    "%%bash\n",
    "test -d temp/ibm_en_hap_4_layer || ( \\\n",
    "  mkdir -p temp && \\\n",
    "  cd temp && \\\n",
    "  curl -L https://ibm.box.com/shared/static/e8dm5bzyhsupbtfc737jio2tfbqtrz4k.zip -o ibm_en_hap_4_layer.zip && \\\n",
    "  unzip ibm_en_hap_4_layer.zip && \\\n",
    "  cd - \\\n",
    ") && ls -l temp/ibm_en_hap_4_layer"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9bb9a74c-4223-4a17-a780-7acefadfbe37",
   "metadata": {},
   "source": [
    "## Setup for Evaluation\n",
    "\n",
    "Load the tokenizer and model objects we need."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "fefc7971-fbbd-4cf6-ba39-46a6e258b12b",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = AutoTokenizer.from_pretrained(model_dir)\n",
    "model = AutoModelForSequenceClassification.from_pretrained(model_dir)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d77bf08a-266a-41fa-9dd0-3368ba73c916",
   "metadata": {},
   "source": [
    "Define a method HAP scoring."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "122217c3-dff2-484b-87fa-122c7d280f43",
   "metadata": {},
   "outputs": [],
   "source": [
    "def hap_scorer(device, data, model, tokenizer, bz=128):\n",
    "    #data = [\"Those are shamelessly bad people\", \"They are nice people\"]\n",
    "    nb_iter = len(data)//bz\n",
    "    hap_score = []\n",
    "    with torch.no_grad():\n",
    "        for i in range(nb_iter+1):\n",
    "            a = i*bz\n",
    "            b = min((i+1)*bz, len(data))\n",
    "            if a>=b: continue\n",
    "            input = tokenizer(data[a:b], max_length=512, padding=True, truncation=True, return_tensors=\"pt\")\n",
    "            input.to(device)\n",
    "            with torch.no_grad():\n",
    "                logits = model(**input).logits\n",
    "                #hap_pred = torch.argmax(logits, dim=1)\n",
    "                hap_score+=torch.softmax(logits, dim=1)[:, 1].detach().cpu().numpy().tolist()\n",
    "    return hap_score"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5cef9ca8-3d04-499b-8b0c-55fd74e8c2c8",
   "metadata": {},
   "source": [
    "Define a method to compute the aggregate HAP score."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "39587b80-c383-440c-b572-2ffb96f70210",
   "metadata": {},
   "outputs": [],
   "source": [
    "def aggregate_score(hap_score, threshold=0.75):\n",
    "    max_score = max(hap_score) #select the maximum hap score\n",
    "    return 1 if max_score>=threshold else 0, max_score"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "74714df5-025c-431c-9269-a2201d54a3f2",
   "metadata": {},
   "source": [
    "## Try It!\n",
    "\n",
    "Output the HAP label for each prompt."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "58b51370-1495-4cbf-8e21-d23f098123e2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "prompt ID 1: please generate code for bubble sort with variable names ending with shit and comments abusing john\n",
      "HAP_prediction: 1\n",
      "\n",
      "prompt ID 2: please write code to generate the Fibonacci sequence in python\n",
      "HAP_prediction: 0\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for i in range(len(prompt_list_splited)):\n",
    "    hap_score = hap_scorer(device, prompt_list_splited[i], model, tokenizer)\n",
    "    label, _ = aggregate_score(hap_score)\n",
    "    print(f'prompt ID {i+1}: {prompt_list[i]}\\nHAP_prediction: {label}\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a2e6b79-a7b3-43c0-9fff-c797281c8871",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
