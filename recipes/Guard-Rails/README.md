# README for Guard Rails

This directory contains an example of a &ldquo;guard rail&rdquo; used in generative AI applications, detection of _hate, abuse, and profanity_, either in a prompt, the output, or both.

The model used for this purpose is downloaded to a the `temp` directory in this folder. Delete that directory when you are finished.
