{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Generate and Execute a Bash Script"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This notebook builds on the [../Text_to_Shell](../Text_to_Shell/Text_to_Shell.ipynb) recipe. Here, the generated Bash code is executed as a system command.\n",
    "\n",
    "> **WARNING:** This recipe executes code generated by language models. The generated code may delete or modify files on your system. Use with caution!\n",
    "\n",
    "See the [../Text_to_Shell](../Text_to_Shell/Text_to_Shell.ipynb) recipe for instructions on installing [Ollama](https://ollama.com/), which you will need, and for information on concepts like _system prompts_ and the differences between commands on different operating systems."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In [../Text_to_Shell](../Text_to_Shell/Text_to_Shell.ipynb), we used a Python helper function to determine the host operating system, MacOS, Linux, etc. We used this information in the prompts to encourage the model to generate shell commands that work on the host system, because some shell commands differ between operating systems. However, the output may still contain commands that are not supported by your operating system. Because this notebook attempts to run the generated commands, you may see failures if an incorrect command syntax was generated."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's begin by repeating some of the code we saw in [../Text_to_Shell](../Text_to_Shell/Text_to_Shell.ipynb), like `pip` installing the Ollama Python API, if needed, defining some data, like the `examples`, and one of the helper functions, `os_name()`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install ollama"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import ollama\n",
    "import os\n",
    "import platform"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def os_name():\n",
    "    os_name = platform.system()\n",
    "    # It turns out, using \"MacOS\" is better than \"Darwin\", which is what gets returned on MacOS. \n",
    "    # For all other cases, the returned value should be fine as is, so we map the result to the desired\n",
    "    # name, but only for MacOS...\n",
    "    name_map = {'Darwin': 'MacOS'}\n",
    "    # ... then pass the os_name value as the second arg, which is used as the default return value.\n",
    "    return name_map.get(os_name, os_name)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stat_flags = '-c \"%y %n\" {}'\n",
    "if os_name() == 'MacOS':\n",
    "    stat_flags = '-f \"%m %N\" {}'\n",
    "print(f\"The 'stat' flags for my OS \\'{os_name()}\\' are \\'{stat_flags}\\'\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "examples = f\"\"\"\n",
    "Question:\n",
    "Recursively find files that match '*.js', and filter out files with 'excludeddir' in their paths.\n",
    "Answer:\n",
    "find . -name '*.js' | grep -v excludeddir\n",
    "\n",
    "Question:\n",
    "Dump \\\"a0b\\\" as hexadecimal bytes\n",
    "Answer:\n",
    "printf \\\"a0b\\\" | od -tx1\n",
    "\n",
    "Question:\n",
    "create a tar ball of all pdf files in the current folder and any subdirectories.\n",
    "Answer:\n",
    "find . -name '*.pdf' | xargs tar czvf pdf.tar\n",
    "\n",
    "Question:\n",
    "Sort all files and directories in the current directory, but no subdirectories, according to modification time, and print only the seven most recently modified items\n",
    "Answer:\n",
    "find . -maxdepth 1 -exec stat {stat_flags} \\; | sort -n -r | tail -n 7\n",
    "\n",
    "Question:\n",
    "find all the empty directories in and under the current directory.\n",
    "Answer:\n",
    "find . -type d -empty\n",
    "\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Writing Prompts for Direct Execution\n",
    "\n",
    "Rather than work through the three successive ways to invoke generation using Ollama, we will just use the `chat()` helper function we used in the previous notebook. \n",
    "\n",
    "But first, we want to modify the _system prompt_ we used in the previous notebook to work better for our purposes.\n",
    "\n",
    "Writing prompts is an art. Recall in [../Text_to_Shell](../Text_to_Shell/Text_to_Shell.ipynb), our output was usually Markdown with quoted sections of shell code and commentary explaining how it worked. Here, we just want code output that we execute without editing. Here are a few tips on writing prompts for our purposes here:\n",
    "\n",
    "> **TIPS:**\n",
    ">\n",
    "> 1. Rather than use a question (\"How do I ...?\") in a prompt, provide a directive (\"Write a script that ...\"). This helps prevent the model from generating dialogue around the code.\n",
    "> 2. Add instructions to the system prompt like this: \"You are a helpful software engineer. You write clear, concise, well-commented code. You only print valid code. You don't print any commentary about the code nor markdown syntax to wrap the code.\" \n",
    "\n",
    "So here is our new system prompt:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "default_system_prompt = f\"\"\"\n",
    "    You are a helpful software engineer. You write clear, concise, \n",
    "    well-commented code. You only print valid code. You don't print \n",
    "    any commentary about the code nor markdown syntax to wrap the code.\n",
    "    You make sure you only generate code that is {os_name()}-compatible!\n",
    "    \"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here is the same `chat()` helper from before."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def chat(prompt: str, \n",
    "         system_prompt:str = default_system_prompt,\n",
    "         examples: str = examples, \n",
    "         model: str ='granite-code:8b') -> str:\n",
    "    user_prompt = f\"\"\"\n",
    "        {examples}\n",
    "        Question:\n",
    "        {prompt}\n",
    "        Answer:\"\"\" \n",
    "    \n",
    "    response = ollama.chat(model=model, messages=[\n",
    "      {\n",
    "        'role':'system',\n",
    "        'content': system_prompt  \n",
    "      },\n",
    "      {\n",
    "        'role': 'user',\n",
    "        'content': user_prompt\n",
    "      },\n",
    "    ])\n",
    "\n",
    "    result = response['message']['content']\n",
    "    print(result)\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bash_code1 = chat(\"\"\"\n",
    "    Write a bash script to print the first 50 files found under the current working directory\n",
    "    that have been modified within the last week. Make sure you show the last modification time \n",
    "    for each file in the output.\"\"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Compare this output to what you got in the [../Text_to_Shell](../Text_to_Shell/Text_to_Shell.ipynb) recipe. Is this output a valid script and nothing else? Or, is there extra commentary and Markdown formatting? If you got this extra, undesirable output, try running the cell again. Does modifying the prompt or system prompt help?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we can attempt to execute the script! There is no need for an additional helper function:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.system(bash_code1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's try another one."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bash_code2 = chat(\"\"\"Write a bash script to recursively find Jupyter notebooks\n",
    "in the parent directory and print their paths.\"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.system(bash_code2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
